{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b5e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3875cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b7afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
    "\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "input_ids = torch.tensor([ids])\n",
    "output = model(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e05a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
      "          2026,  2878,  2166,  1012]])\n",
      "\n",
      "Logits: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Input IDs:\", input_ids)\n",
    "print(\"\")\n",
    "print(\"Logits:\", output.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf83e10",
   "metadata": {},
   "source": [
    "### Task: \n",
    "Apply the tokenization manually on the two sentences used in section 2 (“I’ve been waiting for a HuggingFace course my whole life.” and “I hate this so much!”). Pass them through the model and check that you get the same logits as in section 2. Now batch them together using the padding token, then create the proper attention mask. Check that you obtain the same results when going through the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e71c6271",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\"I’ve been waiting for a HuggingFace course my whole life.\", \n",
    "             \"I hate this so much!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "127272f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# este paso no es necesario\n",
    "tokens = [ tokenizer.tokenize(x) for x in sequences ]\n",
    "ids = [tokenizer.convert_tokens_to_ids(x) for x in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f53984a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1521,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1e61f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5979,  1.6390],\n",
       "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdb7fb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.7801e-02, 9.6220e-01],\n",
       "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictions = torch.nn.functional.softmax(output.logits, dim=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94363d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’ve been waiting for a HuggingFace course my whole life.\n",
      "0.037801433354616165 NEGATIVE\n",
      "0.9621986150741577 POSITIVE\n",
      "\n",
      "\n",
      "I hate this so much!\n",
      "0.9994558691978455 NEGATIVE\n",
      "0.0005441844696179032 POSITIVE\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq, pred, in zip(sequences, predictions):\n",
    "    print(seq)\n",
    "    for pr, tag in zip(pred, model.config.id2label):\n",
    "        print(pr.item(), model.config.id2label[tag])\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
